{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ac9d866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e083d1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "487f68a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "877a9dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>-0.371407</td>\n",
       "      <td>1.341262</td>\n",
       "      <td>0.359894</td>\n",
       "      <td>-0.358091</td>\n",
       "      <td>-0.137134</td>\n",
       "      <td>0.517617</td>\n",
       "      <td>0.401726</td>\n",
       "      <td>-0.058133</td>\n",
       "      <td>0.068653</td>\n",
       "      <td>-0.033194</td>\n",
       "      <td>0.084968</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.229658</td>\n",
       "      <td>0.141004</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>1.202613</td>\n",
       "      <td>0.191881</td>\n",
       "      <td>0.272708</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.081213</td>\n",
       "      <td>0.464960</td>\n",
       "      <td>-0.099254</td>\n",
       "      <td>-1.416907</td>\n",
       "      <td>-0.153826</td>\n",
       "      <td>-0.751063</td>\n",
       "      <td>0.167372</td>\n",
       "      <td>0.050144</td>\n",
       "      <td>-0.443587</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>-0.611987</td>\n",
       "      <td>-0.045575</td>\n",
       "      <td>-0.219633</td>\n",
       "      <td>-0.167716</td>\n",
       "      <td>-0.270710</td>\n",
       "      <td>-0.154104</td>\n",
       "      <td>-0.780055</td>\n",
       "      <td>0.750137</td>\n",
       "      <td>-0.257237</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.644269</td>\n",
       "      <td>1.417964</td>\n",
       "      <td>1.074380</td>\n",
       "      <td>-0.492199</td>\n",
       "      <td>0.948934</td>\n",
       "      <td>0.428118</td>\n",
       "      <td>1.120631</td>\n",
       "      <td>-3.807864</td>\n",
       "      <td>0.615375</td>\n",
       "      <td>1.249376</td>\n",
       "      <td>-0.619468</td>\n",
       "      <td>0.291474</td>\n",
       "      <td>1.757964</td>\n",
       "      <td>-1.323865</td>\n",
       "      <td>0.686133</td>\n",
       "      <td>-0.076127</td>\n",
       "      <td>-1.222127</td>\n",
       "      <td>-0.358222</td>\n",
       "      <td>0.324505</td>\n",
       "      <td>-0.156742</td>\n",
       "      <td>1.943465</td>\n",
       "      <td>-1.015455</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>-0.649709</td>\n",
       "      <td>-0.415267</td>\n",
       "      <td>-0.051634</td>\n",
       "      <td>-1.206921</td>\n",
       "      <td>-1.085339</td>\n",
       "      <td>40.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.894286</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>-0.113192</td>\n",
       "      <td>-0.271526</td>\n",
       "      <td>2.669599</td>\n",
       "      <td>3.721818</td>\n",
       "      <td>0.370145</td>\n",
       "      <td>0.851084</td>\n",
       "      <td>-0.392048</td>\n",
       "      <td>-0.410430</td>\n",
       "      <td>-0.705117</td>\n",
       "      <td>-0.110452</td>\n",
       "      <td>-0.286254</td>\n",
       "      <td>0.074355</td>\n",
       "      <td>-0.328783</td>\n",
       "      <td>-0.210077</td>\n",
       "      <td>-0.499768</td>\n",
       "      <td>0.118765</td>\n",
       "      <td>0.570328</td>\n",
       "      <td>0.052736</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.268092</td>\n",
       "      <td>-0.204233</td>\n",
       "      <td>1.011592</td>\n",
       "      <td>0.373205</td>\n",
       "      <td>-0.384157</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.142404</td>\n",
       "      <td>93.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.338262</td>\n",
       "      <td>1.119593</td>\n",
       "      <td>1.044367</td>\n",
       "      <td>-0.222187</td>\n",
       "      <td>0.499361</td>\n",
       "      <td>-0.246761</td>\n",
       "      <td>0.651583</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>-0.736727</td>\n",
       "      <td>-0.366846</td>\n",
       "      <td>1.017614</td>\n",
       "      <td>0.836390</td>\n",
       "      <td>1.006844</td>\n",
       "      <td>-0.443523</td>\n",
       "      <td>0.150219</td>\n",
       "      <td>0.739453</td>\n",
       "      <td>-0.540980</td>\n",
       "      <td>0.476677</td>\n",
       "      <td>0.451773</td>\n",
       "      <td>0.203711</td>\n",
       "      <td>-0.246914</td>\n",
       "      <td>-0.633753</td>\n",
       "      <td>-0.120794</td>\n",
       "      <td>-0.385050</td>\n",
       "      <td>-0.069733</td>\n",
       "      <td>0.094199</td>\n",
       "      <td>0.246219</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "5   2.0 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n",
       "6   4.0  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708 -0.005159   \n",
       "7   7.0 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118  1.120631   \n",
       "8   7.0 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818  0.370145   \n",
       "9   9.0 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "5  0.260314 -0.568671 -0.371407  1.341262  0.359894 -0.358091 -0.137134   \n",
       "6  0.081213  0.464960 -0.099254 -1.416907 -0.153826 -0.751063  0.167372   \n",
       "7 -3.807864  0.615375  1.249376 -0.619468  0.291474  1.757964 -1.323865   \n",
       "8  0.851084 -0.392048 -0.410430 -0.705117 -0.110452 -0.286254  0.074355   \n",
       "9  0.069539 -0.736727 -0.366846  1.017614  0.836390  1.006844 -0.443523   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "5  0.517617  0.401726 -0.058133  0.068653 -0.033194  0.084968 -0.208254   \n",
       "6  0.050144 -0.443587  0.002821 -0.611987 -0.045575 -0.219633 -0.167716   \n",
       "7  0.686133 -0.076127 -1.222127 -0.358222  0.324505 -0.156742  1.943465   \n",
       "8 -0.328783 -0.210077 -0.499768  0.118765  0.570328  0.052736 -0.073425   \n",
       "9  0.150219  0.739453 -0.540980  0.476677  0.451773  0.203711 -0.246914   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "5 -0.559825 -0.026398 -0.371427 -0.232794  0.105915  0.253844  0.081080   \n",
       "6 -0.270710 -0.154104 -0.780055  0.750137 -0.257237  0.034507  0.005168   \n",
       "7 -1.015455  0.057504 -0.649709 -0.415267 -0.051634 -1.206921 -1.085339   \n",
       "8 -0.268092 -0.204233  1.011592  0.373205 -0.384157  0.011747  0.142404   \n",
       "9 -0.633753 -0.120794 -0.385050 -0.069733  0.094199  0.246219  0.083076   \n",
       "\n",
       "   Amount  Class  \n",
       "0  149.62      0  \n",
       "1    2.69      0  \n",
       "2  378.66      0  \n",
       "3  123.50      0  \n",
       "4   69.99      0  \n",
       "5    3.67      0  \n",
       "6    4.99      0  \n",
       "7   40.80      0  \n",
       "8   93.20      0  \n",
       "9    3.68      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac34156e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>284797</th>\n",
       "      <td>172782.0</td>\n",
       "      <td>-0.241923</td>\n",
       "      <td>0.712247</td>\n",
       "      <td>0.399806</td>\n",
       "      <td>-0.463406</td>\n",
       "      <td>0.244531</td>\n",
       "      <td>-1.343668</td>\n",
       "      <td>0.929369</td>\n",
       "      <td>-0.206210</td>\n",
       "      <td>0.106234</td>\n",
       "      <td>-0.284708</td>\n",
       "      <td>-0.612982</td>\n",
       "      <td>-0.066655</td>\n",
       "      <td>-0.732987</td>\n",
       "      <td>0.237948</td>\n",
       "      <td>-0.293959</td>\n",
       "      <td>-0.245496</td>\n",
       "      <td>-0.174846</td>\n",
       "      <td>-0.891169</td>\n",
       "      <td>-0.290491</td>\n",
       "      <td>-0.139512</td>\n",
       "      <td>-0.228876</td>\n",
       "      <td>-0.514376</td>\n",
       "      <td>0.279598</td>\n",
       "      <td>0.371441</td>\n",
       "      <td>-0.559238</td>\n",
       "      <td>0.113144</td>\n",
       "      <td>0.131507</td>\n",
       "      <td>0.081265</td>\n",
       "      <td>5.49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284798</th>\n",
       "      <td>172782.0</td>\n",
       "      <td>0.219529</td>\n",
       "      <td>0.881246</td>\n",
       "      <td>-0.635891</td>\n",
       "      <td>0.960928</td>\n",
       "      <td>-0.152971</td>\n",
       "      <td>-1.014307</td>\n",
       "      <td>0.427126</td>\n",
       "      <td>0.121340</td>\n",
       "      <td>-0.285670</td>\n",
       "      <td>-0.111640</td>\n",
       "      <td>-1.109232</td>\n",
       "      <td>-0.453235</td>\n",
       "      <td>-1.046946</td>\n",
       "      <td>1.122674</td>\n",
       "      <td>1.243518</td>\n",
       "      <td>-1.431897</td>\n",
       "      <td>0.939328</td>\n",
       "      <td>-0.002373</td>\n",
       "      <td>2.894952</td>\n",
       "      <td>0.006666</td>\n",
       "      <td>0.099936</td>\n",
       "      <td>0.337120</td>\n",
       "      <td>0.251791</td>\n",
       "      <td>0.057688</td>\n",
       "      <td>-1.508368</td>\n",
       "      <td>0.144023</td>\n",
       "      <td>0.181205</td>\n",
       "      <td>0.215243</td>\n",
       "      <td>24.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284799</th>\n",
       "      <td>172783.0</td>\n",
       "      <td>-1.775135</td>\n",
       "      <td>-0.004235</td>\n",
       "      <td>1.189786</td>\n",
       "      <td>0.331096</td>\n",
       "      <td>1.196063</td>\n",
       "      <td>5.519980</td>\n",
       "      <td>-1.518185</td>\n",
       "      <td>2.080825</td>\n",
       "      <td>1.159498</td>\n",
       "      <td>-0.594242</td>\n",
       "      <td>-1.264072</td>\n",
       "      <td>0.453596</td>\n",
       "      <td>-0.243142</td>\n",
       "      <td>-0.858719</td>\n",
       "      <td>-0.766554</td>\n",
       "      <td>-0.644646</td>\n",
       "      <td>0.447184</td>\n",
       "      <td>0.388721</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.348176</td>\n",
       "      <td>0.103302</td>\n",
       "      <td>0.654850</td>\n",
       "      <td>-0.348929</td>\n",
       "      <td>0.745323</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>-0.127579</td>\n",
       "      <td>0.454379</td>\n",
       "      <td>0.130308</td>\n",
       "      <td>79.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284800</th>\n",
       "      <td>172784.0</td>\n",
       "      <td>2.039560</td>\n",
       "      <td>-0.175233</td>\n",
       "      <td>-1.196825</td>\n",
       "      <td>0.234580</td>\n",
       "      <td>-0.008713</td>\n",
       "      <td>-0.726571</td>\n",
       "      <td>0.017050</td>\n",
       "      <td>-0.118228</td>\n",
       "      <td>0.435402</td>\n",
       "      <td>0.267772</td>\n",
       "      <td>0.523316</td>\n",
       "      <td>0.559047</td>\n",
       "      <td>-0.834660</td>\n",
       "      <td>0.626211</td>\n",
       "      <td>-0.541494</td>\n",
       "      <td>0.225361</td>\n",
       "      <td>-0.605252</td>\n",
       "      <td>-0.163049</td>\n",
       "      <td>0.561695</td>\n",
       "      <td>-0.256922</td>\n",
       "      <td>-0.268048</td>\n",
       "      <td>-0.717211</td>\n",
       "      <td>0.297930</td>\n",
       "      <td>-0.359769</td>\n",
       "      <td>-0.315610</td>\n",
       "      <td>0.201114</td>\n",
       "      <td>-0.080826</td>\n",
       "      <td>-0.075071</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284801</th>\n",
       "      <td>172785.0</td>\n",
       "      <td>0.120316</td>\n",
       "      <td>0.931005</td>\n",
       "      <td>-0.546012</td>\n",
       "      <td>-0.745097</td>\n",
       "      <td>1.130314</td>\n",
       "      <td>-0.235973</td>\n",
       "      <td>0.812722</td>\n",
       "      <td>0.115093</td>\n",
       "      <td>-0.204064</td>\n",
       "      <td>-0.657422</td>\n",
       "      <td>0.644837</td>\n",
       "      <td>0.190916</td>\n",
       "      <td>-0.546329</td>\n",
       "      <td>-0.731707</td>\n",
       "      <td>-0.808036</td>\n",
       "      <td>0.599628</td>\n",
       "      <td>0.070441</td>\n",
       "      <td>0.373110</td>\n",
       "      <td>0.128904</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>-0.314205</td>\n",
       "      <td>-0.808520</td>\n",
       "      <td>0.050343</td>\n",
       "      <td>0.102800</td>\n",
       "      <td>-0.435870</td>\n",
       "      <td>0.124079</td>\n",
       "      <td>0.217940</td>\n",
       "      <td>0.068803</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>4.356170</td>\n",
       "      <td>-1.593105</td>\n",
       "      <td>2.711941</td>\n",
       "      <td>-0.689256</td>\n",
       "      <td>4.626942</td>\n",
       "      <td>-0.924459</td>\n",
       "      <td>1.107641</td>\n",
       "      <td>1.991691</td>\n",
       "      <td>0.510632</td>\n",
       "      <td>-0.682920</td>\n",
       "      <td>1.475829</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>-0.975926</td>\n",
       "      <td>-0.150189</td>\n",
       "      <td>0.915802</td>\n",
       "      <td>1.214756</td>\n",
       "      <td>-0.675143</td>\n",
       "      <td>1.164931</td>\n",
       "      <td>-0.711757</td>\n",
       "      <td>-0.025693</td>\n",
       "      <td>-1.221179</td>\n",
       "      <td>-1.545556</td>\n",
       "      <td>0.059616</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>-0.484782</td>\n",
       "      <td>0.411614</td>\n",
       "      <td>0.063119</td>\n",
       "      <td>-0.183699</td>\n",
       "      <td>-0.510602</td>\n",
       "      <td>1.329284</td>\n",
       "      <td>0.140716</td>\n",
       "      <td>0.313502</td>\n",
       "      <td>0.395652</td>\n",
       "      <td>-0.577252</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>-0.399126</td>\n",
       "      <td>-1.933849</td>\n",
       "      <td>-0.962886</td>\n",
       "      <td>-1.042082</td>\n",
       "      <td>0.449624</td>\n",
       "      <td>1.962563</td>\n",
       "      <td>-0.608577</td>\n",
       "      <td>0.509928</td>\n",
       "      <td>1.113981</td>\n",
       "      <td>2.897849</td>\n",
       "      <td>0.127434</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>-0.915427</td>\n",
       "      <td>-1.040458</td>\n",
       "      <td>-0.031513</td>\n",
       "      <td>-0.188093</td>\n",
       "      <td>-0.084316</td>\n",
       "      <td>0.041333</td>\n",
       "      <td>-0.302620</td>\n",
       "      <td>-0.660377</td>\n",
       "      <td>0.167430</td>\n",
       "      <td>-0.256117</td>\n",
       "      <td>0.382948</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "284797  172782.0  -0.241923   0.712247  0.399806 -0.463406  0.244531   \n",
       "284798  172782.0   0.219529   0.881246 -0.635891  0.960928 -0.152971   \n",
       "284799  172783.0  -1.775135  -0.004235  1.189786  0.331096  1.196063   \n",
       "284800  172784.0   2.039560  -0.175233 -1.196825  0.234580 -0.008713   \n",
       "284801  172785.0   0.120316   0.931005 -0.546012 -0.745097  1.130314   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9       V10       V11       V12  \\\n",
       "284797 -1.343668  0.929369 -0.206210  0.106234 -0.284708 -0.612982 -0.066655   \n",
       "284798 -1.014307  0.427126  0.121340 -0.285670 -0.111640 -1.109232 -0.453235   \n",
       "284799  5.519980 -1.518185  2.080825  1.159498 -0.594242 -1.264072  0.453596   \n",
       "284800 -0.726571  0.017050 -0.118228  0.435402  0.267772  0.523316  0.559047   \n",
       "284801 -0.235973  0.812722  0.115093 -0.204064 -0.657422  0.644837  0.190916   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  4.356170 -1.593105  2.711941   \n",
       "284803  1.058415  0.024330  0.294869  0.584800 -0.975926 -0.150189  0.915802   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454 -0.484782  0.411614  0.063119   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087 -0.399126 -1.933849 -0.962886   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180 -0.915427 -1.040458 -0.031513   \n",
       "\n",
       "             V13       V14       V15       V16       V17       V18       V19  \\\n",
       "284797 -0.732987  0.237948 -0.293959 -0.245496 -0.174846 -0.891169 -0.290491   \n",
       "284798 -1.046946  1.122674  1.243518 -1.431897  0.939328 -0.002373  2.894952   \n",
       "284799 -0.243142 -0.858719 -0.766554 -0.644646  0.447184  0.388721  0.792135   \n",
       "284800 -0.834660  0.626211 -0.541494  0.225361 -0.605252 -0.163049  0.561695   \n",
       "284801 -0.546329 -0.731707 -0.808036  0.599628  0.070441  0.373110  0.128904   \n",
       "284802 -0.689256  4.626942 -0.924459  1.107641  1.991691  0.510632 -0.682920   \n",
       "284803  1.214756 -0.675143  1.164931 -0.711757 -0.025693 -1.221179 -1.545556   \n",
       "284804 -0.183699 -0.510602  1.329284  0.140716  0.313502  0.395652 -0.577252   \n",
       "284805 -1.042082  0.449624  1.962563 -0.608577  0.509928  1.113981  2.897849   \n",
       "284806 -0.188093 -0.084316  0.041333 -0.302620 -0.660377  0.167430 -0.256117   \n",
       "\n",
       "             V20       V21       V22       V23       V24       V25       V26  \\\n",
       "284797 -0.139512 -0.228876 -0.514376  0.279598  0.371441 -0.559238  0.113144   \n",
       "284798  0.006666  0.099936  0.337120  0.251791  0.057688 -1.508368  0.144023   \n",
       "284799  0.348176  0.103302  0.654850 -0.348929  0.745323  0.704545 -0.127579   \n",
       "284800 -0.256922 -0.268048 -0.717211  0.297930 -0.359769 -0.315610  0.201114   \n",
       "284801  0.000676 -0.314205 -0.808520  0.050343  0.102800 -0.435870  0.124079   \n",
       "284802  1.475829  0.213454  0.111864  1.014480 -0.509348  1.436807  0.250034   \n",
       "284803  0.059616  0.214205  0.924384  0.012463 -1.016226 -0.606624 -0.395255   \n",
       "284804  0.001396  0.232045  0.578229 -0.037501  0.640134  0.265745 -0.087371   \n",
       "284805  0.127434  0.265245  0.800049 -0.163298  0.123205 -0.569159  0.546668   \n",
       "284806  0.382948  0.261057  0.643078  0.376777  0.008797 -0.473649 -0.818267   \n",
       "\n",
       "             V27       V28  Amount  Class  \n",
       "284797  0.131507  0.081265    5.49      0  \n",
       "284798  0.181205  0.215243   24.05      0  \n",
       "284799  0.454379  0.130308   79.99      0  \n",
       "284800 -0.080826 -0.075071    2.68      0  \n",
       "284801  0.217940  0.068803    2.69      0  \n",
       "284802  0.943651  0.823731    0.77      0  \n",
       "284803  0.068472 -0.053527   24.79      0  \n",
       "284804  0.004455 -0.026561   67.88      0  \n",
       "284805  0.108821  0.104533   10.00      0  \n",
       "284806 -0.002415  0.013649  217.00      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76b709ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(rows,columns) =  (284807, 31)\n"
     ]
    }
   ],
   "source": [
    "print(\"(rows,columns) = \",df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0acad4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efdd9687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39b1877",
   "metadata": {},
   "source": [
    "# Standerd Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "562b7f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "262dbea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "df['Amount'] = sc.fit_transform(pd.DataFrame(df['Amount']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc91a565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>-0.371407</td>\n",
       "      <td>1.341262</td>\n",
       "      <td>0.359894</td>\n",
       "      <td>-0.358091</td>\n",
       "      <td>-0.137134</td>\n",
       "      <td>0.517617</td>\n",
       "      <td>0.401726</td>\n",
       "      <td>-0.058133</td>\n",
       "      <td>0.068653</td>\n",
       "      <td>-0.033194</td>\n",
       "      <td>0.084968</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>-0.338556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.229658</td>\n",
       "      <td>0.141004</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>1.202613</td>\n",
       "      <td>0.191881</td>\n",
       "      <td>0.272708</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.081213</td>\n",
       "      <td>0.464960</td>\n",
       "      <td>-0.099254</td>\n",
       "      <td>-1.416907</td>\n",
       "      <td>-0.153826</td>\n",
       "      <td>-0.751063</td>\n",
       "      <td>0.167372</td>\n",
       "      <td>0.050144</td>\n",
       "      <td>-0.443587</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>-0.611987</td>\n",
       "      <td>-0.045575</td>\n",
       "      <td>-0.219633</td>\n",
       "      <td>-0.167716</td>\n",
       "      <td>-0.270710</td>\n",
       "      <td>-0.154104</td>\n",
       "      <td>-0.780055</td>\n",
       "      <td>0.750137</td>\n",
       "      <td>-0.257237</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>-0.333279</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.644269</td>\n",
       "      <td>1.417964</td>\n",
       "      <td>1.074380</td>\n",
       "      <td>-0.492199</td>\n",
       "      <td>0.948934</td>\n",
       "      <td>0.428118</td>\n",
       "      <td>1.120631</td>\n",
       "      <td>-3.807864</td>\n",
       "      <td>0.615375</td>\n",
       "      <td>1.249376</td>\n",
       "      <td>-0.619468</td>\n",
       "      <td>0.291474</td>\n",
       "      <td>1.757964</td>\n",
       "      <td>-1.323865</td>\n",
       "      <td>0.686133</td>\n",
       "      <td>-0.076127</td>\n",
       "      <td>-1.222127</td>\n",
       "      <td>-0.358222</td>\n",
       "      <td>0.324505</td>\n",
       "      <td>-0.156742</td>\n",
       "      <td>1.943465</td>\n",
       "      <td>-1.015455</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>-0.649709</td>\n",
       "      <td>-0.415267</td>\n",
       "      <td>-0.051634</td>\n",
       "      <td>-1.206921</td>\n",
       "      <td>-1.085339</td>\n",
       "      <td>-0.190107</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.894286</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>-0.113192</td>\n",
       "      <td>-0.271526</td>\n",
       "      <td>2.669599</td>\n",
       "      <td>3.721818</td>\n",
       "      <td>0.370145</td>\n",
       "      <td>0.851084</td>\n",
       "      <td>-0.392048</td>\n",
       "      <td>-0.410430</td>\n",
       "      <td>-0.705117</td>\n",
       "      <td>-0.110452</td>\n",
       "      <td>-0.286254</td>\n",
       "      <td>0.074355</td>\n",
       "      <td>-0.328783</td>\n",
       "      <td>-0.210077</td>\n",
       "      <td>-0.499768</td>\n",
       "      <td>0.118765</td>\n",
       "      <td>0.570328</td>\n",
       "      <td>0.052736</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.268092</td>\n",
       "      <td>-0.204233</td>\n",
       "      <td>1.011592</td>\n",
       "      <td>0.373205</td>\n",
       "      <td>-0.384157</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.142404</td>\n",
       "      <td>0.019392</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.338262</td>\n",
       "      <td>1.119593</td>\n",
       "      <td>1.044367</td>\n",
       "      <td>-0.222187</td>\n",
       "      <td>0.499361</td>\n",
       "      <td>-0.246761</td>\n",
       "      <td>0.651583</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>-0.736727</td>\n",
       "      <td>-0.366846</td>\n",
       "      <td>1.017614</td>\n",
       "      <td>0.836390</td>\n",
       "      <td>1.006844</td>\n",
       "      <td>-0.443523</td>\n",
       "      <td>0.150219</td>\n",
       "      <td>0.739453</td>\n",
       "      <td>-0.540980</td>\n",
       "      <td>0.476677</td>\n",
       "      <td>0.451773</td>\n",
       "      <td>0.203711</td>\n",
       "      <td>-0.246914</td>\n",
       "      <td>-0.633753</td>\n",
       "      <td>-0.120794</td>\n",
       "      <td>-0.385050</td>\n",
       "      <td>-0.069733</td>\n",
       "      <td>0.094199</td>\n",
       "      <td>0.246219</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>-0.338516</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "5   2.0 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n",
       "6   4.0  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708 -0.005159   \n",
       "7   7.0 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118  1.120631   \n",
       "8   7.0 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818  0.370145   \n",
       "9   9.0 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "5  0.260314 -0.568671 -0.371407  1.341262  0.359894 -0.358091 -0.137134   \n",
       "6  0.081213  0.464960 -0.099254 -1.416907 -0.153826 -0.751063  0.167372   \n",
       "7 -3.807864  0.615375  1.249376 -0.619468  0.291474  1.757964 -1.323865   \n",
       "8  0.851084 -0.392048 -0.410430 -0.705117 -0.110452 -0.286254  0.074355   \n",
       "9  0.069539 -0.736727 -0.366846  1.017614  0.836390  1.006844 -0.443523   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "5  0.517617  0.401726 -0.058133  0.068653 -0.033194  0.084968 -0.208254   \n",
       "6  0.050144 -0.443587  0.002821 -0.611987 -0.045575 -0.219633 -0.167716   \n",
       "7  0.686133 -0.076127 -1.222127 -0.358222  0.324505 -0.156742  1.943465   \n",
       "8 -0.328783 -0.210077 -0.499768  0.118765  0.570328  0.052736 -0.073425   \n",
       "9  0.150219  0.739453 -0.540980  0.476677  0.451773  0.203711 -0.246914   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "5 -0.559825 -0.026398 -0.371427 -0.232794  0.105915  0.253844  0.081080   \n",
       "6 -0.270710 -0.154104 -0.780055  0.750137 -0.257237  0.034507  0.005168   \n",
       "7 -1.015455  0.057504 -0.649709 -0.415267 -0.051634 -1.206921 -1.085339   \n",
       "8 -0.268092 -0.204233  1.011592  0.373205 -0.384157  0.011747  0.142404   \n",
       "9 -0.633753 -0.120794 -0.385050 -0.069733  0.094199  0.246219  0.083076   \n",
       "\n",
       "     Amount  Class  \n",
       "0  0.244964      0  \n",
       "1 -0.342475      0  \n",
       "2  1.160686      0  \n",
       "3  0.140534      0  \n",
       "4 -0.073403      0  \n",
       "5 -0.338556      0  \n",
       "6 -0.333279      0  \n",
       "7 -0.190107      0  \n",
       "8  0.019392      0  \n",
       "9 -0.338516      0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dae63355",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Time'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "faa385d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22fff9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03dbd947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275663, 30)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fe525d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    275190\n",
       "1       473\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89c72c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a5201dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: ylabel='count'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlUAAAGdCAYAAAA7VYb2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAmB0lEQVR4nO3dcVDUdf7H8RdgLKTukgqs+3NTyi7lJJnQcO/KXybjetHNeNHvp+YUGenoD/ydbinSGWq/bpifTb+00+TXNR3eTP7OvN9P+wUXxQ8Tf5ekF8YZ/oIxf/7GGl2kDDZJAWF/fzR8x01NxI8tyPMxszPt9/tmebP9wXOW764RwWAwKAAAAFyVyHAvAAAAcD0gqgAAAAwgqgAAAAwgqgAAAAwgqgAAAAwgqgAAAAwgqgAAAAwgqgAAAAwYFO4FBpKuri4dP35cQ4cOVURERLjXAQAAPRAMBvX111/L5XIpMvLSr0cRVT+g48ePy+12h3sNAADQC5999plGjRp1yfNE1Q9o6NChkr79n2K328O8DQAA6IlAICC32239Hr8UouoH1P0nP7vdTlQBANDPXO7SHS5UBwAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMGBQuBdA/5S2/PfhXgEA0A/UPP9ouFf4wfBKFQAAgAFEFQAAgAFEFQAAgAFEFQAAgAFEFQAAgAFEFQAAgAFEFQAAgAFEFQAAgAFEFQAAgAFEFQAAgAFEFQAAgAFEFQAAgAFEFQAAgAFEFQAAgAFEFQAAgAFEFQAAgAFEFQAAgAFEFQAAgAFEFQAAgAFEFQAAgAFEFQAAgAFEFQAAgAFEFQAAgAFEFQAAgAFEFQAAgAFEFQAAgAFEFQAAgAFEFQAAgAFhjaqioiJNnjxZQ4cOVUJCgmbNmqWGhoaQmXvvvVcREREht0WLFoXMHDt2TJmZmbrxxhuVkJCg5cuX69y5cyEzu3fv1p133imbzaaxY8eqpKTkgn02bdqkMWPGKCYmRunp6dq/f3/I+bNnzyo3N1fDhw/XkCFDlJWVpcbGRjNPBgAA6NfCGlVVVVXKzc3VBx98oIqKCnV0dGjGjBlqbW0NmVuwYIFOnDhh3datW2ed6+zsVGZmptrb27V3715t2bJFJSUlKiwstGaOHj2qzMxMTZs2TbW1tVq6dKmeeOIJvfPOO9bMtm3b5PP5tHr1ah04cEATJ06U1+vVyZMnrZlly5bprbfe0vbt21VVVaXjx4/rwQcfvIbPEAAA6C8igsFgMNxLdGtqalJCQoKqqqo0depUSd++UpWamqr169df9GvefvttPfDAAzp+/LgSExMlScXFxcrPz1dTU5Oio6OVn5+vsrIy1dXVWV83Z84cNTc3q7y8XJKUnp6uyZMna+PGjZKkrq4uud1uLVmyRCtXrlRLS4vi4+O1detWPfTQQ5Kk+vp6jR8/XtXV1ZoyZcplf75AICCHw6GWlhbZ7fZeP099Qdry34d7BQBAP1Dz/KPhXuGq9fT3d5+6pqqlpUWSNGzYsJDjr7/+ukaMGKEJEyaooKBA33zzjXWuurpaKSkpVlBJktfrVSAQ0KFDh6yZjIyMkMf0er2qrq6WJLW3t6umpiZkJjIyUhkZGdZMTU2NOjo6QmbGjRunm2++2Zr5rra2NgUCgZAbAAC4Pg0K9wLdurq6tHTpUv30pz/VhAkTrOMPP/ywRo8eLZfLpYMHDyo/P18NDQ36j//4D0mS3+8PCSpJ1n2/3/+9M4FAQGfOnNFXX32lzs7Oi87U19dbjxEdHa24uLgLZrq/z3cVFRVp7dq1V/hMAACA/qjPRFVubq7q6ur05z//OeT4woULrf9OSUnRyJEjNX36dB05ckS33nrrD73mFSkoKJDP57PuBwIBud3uMG4EAACulT7x57+8vDyVlpbqvffe06hRo753Nj09XZL06aefSpKcTucF78Drvu90Or93xm63KzY2ViNGjFBUVNRFZ85/jPb2djU3N19y5rtsNpvsdnvIDQAAXJ/CGlXBYFB5eXnasWOHdu3apaSkpMt+TW1trSRp5MiRkiSPx6OPP/445F16FRUVstvtSk5OtmYqKytDHqeiokIej0eSFB0drbS0tJCZrq4uVVZWWjNpaWm64YYbQmYaGhp07NgxawYAAAxcYf3zX25urrZu3ao333xTQ4cOta5Ncjgcio2N1ZEjR7R161bdf//9Gj58uA4ePKhly5Zp6tSpuuOOOyRJM2bMUHJysh555BGtW7dOfr9fq1atUm5urmw2myRp0aJF2rhxo1asWKHHH39cu3bt0htvvKGysjJrF5/Pp+zsbE2aNEl33XWX1q9fr9bWVs2fP9/aKScnRz6fT8OGDZPdbteSJUvk8Xh69M4/AABwfQtrVG3evFnStx+bcL7f/e53euyxxxQdHa3/+q//sgLH7XYrKytLq1atsmajoqJUWlqqxYsXy+PxaPDgwcrOztazzz5rzSQlJamsrEzLli3Thg0bNGrUKL366qvyer3WzOzZs9XU1KTCwkL5/X6lpqaqvLw85OL1F198UZGRkcrKylJbW5u8Xq9efvnla/TsAACA/qRPfU7V9Y7PqQIADDR8ThUAAACuCFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgQFijqqioSJMnT9bQoUOVkJCgWbNmqaGhIWTm7Nmzys3N1fDhwzVkyBBlZWWpsbExZObYsWPKzMzUjTfeqISEBC1fvlznzp0Lmdm9e7fuvPNO2Ww2jR07ViUlJRfss2nTJo0ZM0YxMTFKT0/X/v37r3gXAAAwMIU1qqqqqpSbm6sPPvhAFRUV6ujo0IwZM9Ta2mrNLFu2TG+99Za2b9+uqqoqHT9+XA8++KB1vrOzU5mZmWpvb9fevXu1ZcsWlZSUqLCw0Jo5evSoMjMzNW3aNNXW1mrp0qV64okn9M4771gz27Ztk8/n0+rVq3XgwAFNnDhRXq9XJ0+e7PEuAABg4IoIBoPBcC/RrampSQkJCaqqqtLUqVPV0tKi+Ph4bd26VQ899JAkqb6+XuPHj1d1dbWmTJmit99+Ww888ICOHz+uxMRESVJxcbHy8/PV1NSk6Oho5efnq6ysTHV1ddb3mjNnjpqbm1VeXi5JSk9P1+TJk7Vx40ZJUldXl9xut5YsWaKVK1f2aJfLCQQCcjgcamlpkd1uN/rc/dDSlv8+3CsAAPqBmucfDfcKV62nv7/71DVVLS0tkqRhw4ZJkmpqatTR0aGMjAxrZty4cbr55ptVXV0tSaqurlZKSooVVJLk9XoVCAR06NAha+b8x+ie6X6M9vZ21dTUhMxERkYqIyPDmunJLt/V1tamQCAQcgMAANenPhNVXV1dWrp0qX76059qwoQJkiS/36/o6GjFxcWFzCYmJsrv91sz5wdV9/nuc983EwgEdObMGX3xxRfq7Oy86Mz5j3G5Xb6rqKhIDofDurnd7h4+GwAAoL/pM1GVm5ururo6/eEPfwj3KsYUFBSopaXFun322WfhXgkAAFwjg8K9gCTl5eWptLRUe/bs0ahRo6zjTqdT7e3tam5uDnmFqLGxUU6n05r57rv0ut+Rd/7Md9+l19jYKLvdrtjYWEVFRSkqKuqiM+c/xuV2+S6bzSabzXYFzwQAAOivwvpKVTAYVF5ennbs2KFdu3YpKSkp5HxaWppuuOEGVVZWWscaGhp07NgxeTweSZLH49HHH38c8i69iooK2e12JScnWzPnP0b3TPdjREdHKy0tLWSmq6tLlZWV1kxPdgEAAANXWF+pys3N1datW/Xmm29q6NCh1rVJDodDsbGxcjgcysnJkc/n07Bhw2S327VkyRJ5PB7r3XYzZsxQcnKyHnnkEa1bt05+v1+rVq1Sbm6u9SrRokWLtHHjRq1YsUKPP/64du3apTfeeENlZWXWLj6fT9nZ2Zo0aZLuuusurV+/Xq2trZo/f7610+V2AQAAA1dYo2rz5s2SpHvvvTfk+O9+9zs99thjkqQXX3xRkZGRysrKUltbm7xer15++WVrNioqSqWlpVq8eLE8Ho8GDx6s7OxsPfvss9ZMUlKSysrKtGzZMm3YsEGjRo3Sq6++Kq/Xa83Mnj1bTU1NKiwslN/vV2pqqsrLy0MuXr/cLgAAYODqU59Tdb3jc6oAAAMNn1MFAACAK0JUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGNCrqLrvvvvU3Nx8wfFAIKD77rvvancCAADod3oVVbt371Z7e/sFx8+ePav//u//vuqlAAAA+ptBVzJ88OBB67//53/+R36/37rf2dmp8vJy/c3f/I257QAAAPqJK4qq1NRURUREKCIi4qJ/5ouNjdVvfvMbY8sBAAD0F1cUVUePHlUwGNQtt9yi/fv3Kz4+3joXHR2thIQERUVFGV8SAACgr7uiqBo9erQkqaur65osAwAA0F9dUVSd7/Dhw3rvvfd08uTJCyKrsLDwqhcDAADoT3r17r/f/va3Gj9+vAoLC/XHP/5RO3bssG47d+7s8ePs2bNHP//5z+VyuRQREXHB1z722GPWNVzdt5kzZ4bMnDp1SvPmzZPdbldcXJxycnJ0+vTpkJmDBw/qnnvuUUxMjNxut9atW3fBLtu3b9e4ceMUExOjlJQU/elPfwo5HwwGVVhYqJEjRyo2NlYZGRk6fPhwj39WAABwfetVVD333HP69a9/Lb/fr9raWn300UfW7cCBAz1+nNbWVk2cOFGbNm265MzMmTN14sQJ6/Zv//ZvIefnzZunQ4cOqaKiQqWlpdqzZ48WLlxonQ8EApoxY4ZGjx6tmpoaPf/881qzZo1eeeUVa2bv3r2aO3eucnJy9NFHH2nWrFmaNWuW6urqrJl169bppZdeUnFxsfbt26fBgwfL6/Xq7NmzPf55AQDA9SsiGAwGr/SL7Ha7amtrdcstt5hbJCJCO3bs0KxZs6xjjz32mJqbmy/56tcnn3yi5ORk/eUvf9GkSZMkSeXl5br//vv1+eefy+VyafPmzfrVr34lv9+v6OhoSdLKlSu1c+dO1dfXS5Jmz56t1tZWlZaWWo89ZcoUpaamqri4WMFgUC6XS08++aSeeuopSVJLS4sSExNVUlKiOXPm9OhnDAQCcjgcamlpkd1uv9KnqE9JW/77cK8AAOgHap5/NNwrXLWe/v7u1StVf/d3f6d3332318tdid27dyshIUG33367Fi9erC+//NI6V11drbi4OCuoJCkjI0ORkZHat2+fNTN16lQrqCTJ6/WqoaFBX331lTWTkZER8n29Xq+qq6slffuuR7/fHzLjcDiUnp5uzVxMW1ubAoFAyA0AAFyfenWh+tixY/XMM8/ogw8+UEpKim644YaQ8//4j/9oZLmZM2fqwQcfVFJSko4cOaKnn35aP/vZz1RdXa2oqCj5/X4lJCSEfM2gQYM0bNgw64NJ/X6/kpKSQmYSExOtczfddJP8fr917PyZ8x/j/K+72MzFFBUVae3atb34yQEAQH/Tq6h65ZVXNGTIEFVVVamqqirkXEREhLGoOv/PaikpKbrjjjt06623avfu3Zo+fbqR73EtFRQUyOfzWfcDgYDcbncYNwIAANdKr6Lq6NGjpvfokVtuuUUjRozQp59+qunTp8vpdOrkyZMhM+fOndOpU6fkdDolSU6nU42NjSEz3fcvN3P++e5jI0eODJlJTU295L42m002m60XPykAAOhvenVNVbh8/vnn+vLLL62w8Xg8am5uVk1NjTWza9cudXV1KT093ZrZs2ePOjo6rJmKigrdfvvtuummm6yZysrKkO9VUVEhj8cjSUpKSpLT6QyZCQQC2rdvnzUDAAAGtl69UvX4449/7/nXXnutR49z+vRpffrpp9b9o0ePqra2VsOGDdOwYcO0du1aZWVlyel06siRI1qxYoXGjh0rr9crSRo/frxmzpypBQsWqLi4WB0dHcrLy9OcOXPkcrkkSQ8//LDWrl2rnJwc5efnq66uThs2bNCLL75ofd9f/vKX+tu//Vu98MILyszM1B/+8Ad9+OGH1scuREREaOnSpXruued02223KSkpSc8884xcLlfIuxUBAMDA1auo6n7XXLeOjg7V1dWpubn5ov/Q8qV8+OGHmjZtmnW/+/qj7Oxsbd68WQcPHtSWLVvU3Nwsl8ulGTNm6J/+6Z9C/qT2+uuvKy8vT9OnT1dkZKSysrL00ksvWecdDofeffdd5ebmKi0tTSNGjFBhYWHIZ1n95Cc/0datW7Vq1So9/fTTuu2227Rz505NmDDBmlmxYoVaW1u1cOFCNTc36+6771Z5ebliYmJ6/sQBAIDrVq8+p+piurq6tHjxYt16661asWKFiYe87vA5VQCAgYbPqeqFyMhI+Xy+kD+rAQAADBRGL1Q/cuSIzp07Z/IhAQAA+oVeXVN1/mcvSd/+Y8MnTpxQWVmZsrOzjSwGAADQn/Qqqj766KOQ+5GRkYqPj9cLL7xw2XcGAgAAXI96FVXvvfee6T0AAAD6tV5FVbempiY1NDRIkm6//XbFx8cbWQoAAKC/6dWF6q2trXr88cc1cuRITZ06VVOnTpXL5VJOTo6++eYb0zsCAAD0eb2KKp/Pp6qqKr311ltqbm5Wc3Oz3nzzTVVVVenJJ580vSMAAECf16s///37v/+7/vjHP+ree++1jt1///2KjY3V3//932vz5s2m9gMAAOgXevVK1TfffKPExMQLjickJPDnPwAAMCD1Kqo8Ho9Wr16ts2fPWsfOnDmjtWvXyuPxGFsOAACgv+jVn//Wr1+vmTNnatSoUZo4caIk6a9//atsNpveffddowsCAAD0B72KqpSUFB0+fFivv/666uvrJUlz587VvHnzFBsba3RBAACA/qBXUVVUVKTExEQtWLAg5Phrr72mpqYm5efnG1kOAACgv+jVNVX/+q//qnHjxl1w/Mc//rGKi4uveikAAID+pldR5ff7NXLkyAuOx8fH68SJE1e9FAAAQH/Tq6hyu916//33Lzj+/vvvy+VyXfVSAAAA/U2vrqlasGCBli5dqo6ODt13332SpMrKSq1YsYJPVAcAAANSr6Jq+fLl+vLLL/UP//APam9vlyTFxMQoPz9fBQUFRhcEAADoD3oVVREREfrnf/5nPfPMM/rkk08UGxur2267TTabzfR+AAAA/UKvoqrbkCFDNHnyZFO7AAAA9Fu9ulAdAAAAoYgqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA8IaVXv27NHPf/5zuVwuRUREaOfOnSHng8GgCgsLNXLkSMXGxiojI0OHDx8OmTl16pTmzZsnu92uuLg45eTk6PTp0yEzBw8e1D333KOYmBi53W6tW7fugl22b9+ucePGKSYmRikpKfrTn/50xbsAAICBK6xR1draqokTJ2rTpk0XPb9u3Tq99NJLKi4u1r59+zR48GB5vV6dPXvWmpk3b54OHTqkiooKlZaWas+ePVq4cKF1PhAIaMaMGRo9erRqamr0/PPPa82aNXrllVesmb1792ru3LnKycnRRx99pFmzZmnWrFmqq6u7ol0AAMDAFREMBoPhXkKSIiIitGPHDs2aNUvSt68MuVwuPfnkk3rqqackSS0tLUpMTFRJSYnmzJmjTz75RMnJyfrLX/6iSZMmSZLKy8t1//336/PPP5fL5dLmzZv1q1/9Sn6/X9HR0ZKklStXaufOnaqvr5ckzZ49W62trSotLbX2mTJlilJTU1VcXNyjXXoiEAjI4XCopaVFdrvdyPMWLmnLfx/uFQAA/UDN84+Ge4Wr1tPf3332mqqjR4/K7/crIyPDOuZwOJSenq7q6mpJUnV1teLi4qygkqSMjAxFRkZq37591szUqVOtoJIkr9erhoYGffXVV9bM+d+ne6b7+/RkFwAAMLANCvcCl+L3+yVJiYmJIccTExOtc36/XwkJCSHnBw0apGHDhoXMJCUlXfAY3eduuukm+f3+y36fy+1yMW1tbWpra7PuBwKB7/mJAQBAf9ZnX6m6HhQVFcnhcFg3t9sd7pUAAMA10mejyul0SpIaGxtDjjc2NlrnnE6nTp48GXL+3LlzOnXqVMjMxR7j/O9xqZnzz19ul4spKChQS0uLdfvss88u81MDAID+qs9GVVJSkpxOpyorK61jgUBA+/btk8fjkSR5PB41NzerpqbGmtm1a5e6urqUnp5uzezZs0cdHR3WTEVFhW6//XbddNNN1sz536d7pvv79GSXi7HZbLLb7SE3AABwfQprVJ0+fVq1tbWqra2V9O0F4bW1tTp27JgiIiK0dOlSPffcc/rP//xPffzxx3r00UflcrmsdwiOHz9eM2fO1IIFC7R//369//77ysvL05w5c+RyuSRJDz/8sKKjo5WTk6NDhw5p27Zt2rBhg3w+n7XHL3/5S5WXl+uFF15QfX291qxZow8//FB5eXmS1KNdAADAwBbWC9U//PBDTZs2zbrfHTrZ2dkqKSnRihUr1NraqoULF6q5uVl33323ysvLFRMTY33N66+/rry8PE2fPl2RkZHKysrSSy+9ZJ13OBx69913lZubq7S0NI0YMUKFhYUhn2X1k5/8RFu3btWqVav09NNP67bbbtPOnTs1YcIEa6YnuwAAgIGrz3xO1UDA51QBAAYaPqcKAAAAV4SoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMKBPR9WaNWsUERERchs3bpx1/uzZs8rNzdXw4cM1ZMgQZWVlqbGxMeQxjh07pszMTN14441KSEjQ8uXLde7cuZCZ3bt3684775TNZtPYsWNVUlJywS6bNm3SmDFjFBMTo/T0dO3fv/+a/MwAAKB/6tNRJUk//vGPdeLECev25z//2Tq3bNkyvfXWW9q+fbuqqqp0/PhxPfjgg9b5zs5OZWZmqr29XXv37tWWLVtUUlKiwsJCa+bo0aPKzMzUtGnTVFtbq6VLl+qJJ57QO++8Y81s27ZNPp9Pq1ev1oEDBzRx4kR5vV6dPHnyh3kSAABAnxcRDAaD4V7iUtasWaOdO3eqtrb2gnMtLS2Kj4/X1q1b9dBDD0mS6uvrNX78eFVXV2vKlCl6++239cADD+j48eNKTEyUJBUXFys/P19NTU2Kjo5Wfn6+ysrKVFdXZz32nDlz1NzcrPLycklSenq6Jk+erI0bN0qSurq65Ha7tWTJEq1cubLHP08gEJDD4VBLS4vsdntvn5Y+IW3578O9AgCgH6h5/tFwr3DVevr7u8+/UnX48GG5XC7dcsstmjdvno4dOyZJqqmpUUdHhzIyMqzZcePG6eabb1Z1dbUkqbq6WikpKVZQSZLX61UgENChQ4esmfMfo3um+zHa29tVU1MTMhMZGamMjAxr5lLa2toUCARCbgAA4PrUp6MqPT1dJSUlKi8v1+bNm3X06FHdc889+vrrr+X3+xUdHa24uLiQr0lMTJTf75ck+f3+kKDqPt997vtmAoGAzpw5oy+++EKdnZ0Xnel+jEspKiqSw+Gwbm63+4qfAwAA0D8MCvcC3+dnP/uZ9d933HGH0tPTNXr0aL3xxhuKjY0N42Y9U1BQIJ/PZ90PBAKEFQAA16k+/UrVd8XFxelHP/qRPv30UzmdTrW3t6u5uTlkprGxUU6nU5LkdDoveDdg9/3LzdjtdsXGxmrEiBGKioq66Ez3Y1yKzWaT3W4PuQEAgOtTv4qq06dP68iRIxo5cqTS0tJ0ww03qLKy0jrf0NCgY8eOyePxSJI8Ho8+/vjjkHfpVVRUyG63Kzk52Zo5/zG6Z7ofIzo6WmlpaSEzXV1dqqystGYAAAD6dFQ99dRTqqqq0v/93/9p7969+sUvfqGoqCjNnTtXDodDOTk58vl8eu+991RTU6P58+fL4/FoypQpkqQZM2YoOTlZjzzyiP7617/qnXfe0apVq5SbmyubzSZJWrRokf73f/9XK1asUH19vV5++WW98cYbWrZsmbWHz+fTb3/7W23ZskWffPKJFi9erNbWVs2fPz8szwsAAOh7+vQ1VZ9//rnmzp2rL7/8UvHx8br77rv1wQcfKD4+XpL04osvKjIyUllZWWpra5PX69XLL79sfX1UVJRKS0u1ePFieTweDR48WNnZ2Xr22WetmaSkJJWVlWnZsmXasGGDRo0apVdffVVer9eamT17tpqamlRYWCi/36/U1FSVl5dfcPE6AAAYuPr051Rdb/icKgDAQMPnVAEAAOCKEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFVXaNOmTRozZoxiYmKUnp6u/fv3h3slAADQBxBVV2Dbtm3y+XxavXq1Dhw4oIkTJ8rr9erkyZPhXg0AAIQZUXUF/uVf/kULFizQ/PnzlZycrOLiYt1444167bXXwr0aAAAIs0HhXqC/aG9vV01NjQoKCqxjkZGRysjIUHV19UW/pq2tTW1tbdb9lpYWSVIgELi2y/4AOtvOhHsFAEA/cD38zuv+GYLB4PfOEVU99MUXX6izs1OJiYkhxxMTE1VfX3/RrykqKtLatWsvOO52u6/JjgAA9DWO3ywK9wrGfP3113I4HJc8T1RdQwUFBfL5fNb9rq4unTp1SsOHD1dEREQYNwNgWiAQkNvt1meffSa73R7udQAYFAwG9fXXX8vlcn3vHFHVQyNGjFBUVJQaGxtDjjc2NsrpdF70a2w2m2w2W8ixuLi4a7UigD7AbrcTVcB16PteoerGheo9FB0drbS0NFVWVlrHurq6VFlZKY/HE8bNAABAX8ArVVfA5/MpOztbkyZN0l133aX169ertbVV8+fPD/dqAAAgzIiqKzB79mw1NTWpsLBQfr9fqampKi8vv+DidQADj81m0+rVqy/4kz+AgSMieLn3BwIAAOCyuKYKAADAAKIKAADAAKIKAADAAKIKAADAAKIKAK7Spk2bNGbMGMXExCg9PV379+8P90oAwoCoAoCrsG3bNvl8Pq1evVoHDhzQxIkT5fV6dfLkyXCvBuAHxkcqAMBVSE9P1+TJk7Vx40ZJ3/5LC263W0uWLNHKlSvDvB2AHxKvVAFAL7W3t6umpkYZGRnWscjISGVkZKi6ujqMmwEIB6IKAHrpiy++UGdn5wX/qkJiYqL8fn+YtgIQLkQVAACAAUQVAPTSiBEjFBUVpcbGxpDjjY2NcjqdYdoKQLgQVQDQS9HR0UpLS1NlZaV1rKurS5WVlfJ4PGHcDEA4DAr3AgDQn/l8PmVnZ2vSpEm66667tH79erW2tmr+/PnhXg3AD4yoAoCrMHv2bDU1NamwsFB+v1+pqakqLy+/4OJ1ANc/PqcKAADAAK6pAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMICoAgAAMOD/AdwSwEmkkSAjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1260738",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('Class',axis=1)\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89246a02",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "edefff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "475b9447",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest = train_test_split(x,y,random_state=10,test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e246fda",
   "metadata": {},
   "source": [
    "# Training without Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0bbdce4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0796dd91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f83a7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = model.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8dc6f4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c2c6be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99927448170787"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytest,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a1c24b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8513513513513513"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(ytest,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2bd5ae5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6847826086956522"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(ytest,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a55ecc27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7590361445783131"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(ytest,ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c4da64",
   "metadata": {},
   "source": [
    "# 1. UNDER SAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e63a156",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = df[df['Class']==0]\n",
    "fraud = df[df['Class']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ced626f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((275190, 30), (473, 30))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal.shape,fraud.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "09a499bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_sample = normal.sample(n=473)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0cdd2f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(473, 30)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f0e25ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df  = pd.concat([normal_sample,fraud],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7b897a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    473\n",
       "1    473\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d3334e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_df.drop('Class',axis=1)\n",
    "Y = new_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "af723a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain,Xtest,Ytrain,Ytest = train_test_split(X,Y,random_state=10,test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81e8e9d",
   "metadata": {},
   "source": [
    "# 1.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a7412a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(Xtrain,Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "85d90756",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_ypred0 = lr.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c9459d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9315789473684211"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Ytest,lr_ypred0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9bc2446e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9534883720930233"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(Ytest,lr_ypred0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "076658e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9010989010989011"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(Ytest,lr_ypred0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "783b75bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9265536723163842"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Ytest,lr_ypred0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15eb6c8",
   "metadata": {},
   "source": [
    "# 1.2 Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "12bcf310",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a90a14dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c5eaf974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.fit(Xtrain,Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "50ce0d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_ypred0 = dt.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "43d36e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8947368421052632"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Ytest,dt_ypred0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0aabf894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8817204301075269"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(Ytest,dt_ypred0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8a6ff464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9010989010989011"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(Ytest,dt_ypred0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7e0c4708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8913043478260869"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Ytest,dt_ypred0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4399266f",
   "metadata": {},
   "source": [
    "# 1.3 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4c134c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e38eafe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(Xtrain,Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3faf1ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_ypred0 = rf.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "19e97b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9105263157894737"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Ytest,rf_ypred0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "acbabda2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9302325581395349"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(Ytest,rf_ypred0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9e76e26d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8791208791208791"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(Ytest,rf_ypred0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "37096d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9039548022598871"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Ytest,rf_ypred0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b6079d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.931579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DTC</td>\n",
       "      <td>0.894737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.910526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Models  Accuracy\n",
       "0     LR  0.931579\n",
       "1    DTC  0.894737\n",
       "2     rf  0.910526"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ACCURACY CHECK\n",
    "final_data = pd.DataFrame({'Models':['LR','DTC','rf'],\n",
    "             'Accuracy':[accuracy_score(Ytest,lr_ypred0),\n",
    "                         accuracy_score(Ytest,dt_ypred0),\n",
    "                         accuracy_score(Ytest,rf_ypred0)]})\n",
    "final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02554c3",
   "metadata": {},
   "source": [
    "# 2. OVER SAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1e5e9ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('Class',axis=1)\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "852fe6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((275663, 29), (275663,))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f1c354ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "82fed547",
   "metadata": {},
   "outputs": [],
   "source": [
    "xres,yres = SMOTE().fit_resample(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2edaa491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    275190\n",
       "1    275190\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yres.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ab5e32b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest = train_test_split(xres,yres,random_state=10,test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee6728a",
   "metadata": {},
   "source": [
    "# 2.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ca5942e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = LogisticRegression()\n",
    "log.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4f905064",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_ypred1 = log.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7ac3a8bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9451015661906319"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytest,lr_ypred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2ca89587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9732719607008857"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(ytest,lr_ypred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "79678f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9152314267527507"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(ytest,lr_ypred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "55291646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9433597960465269"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(ytest,lr_ypred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707a63f7",
   "metadata": {},
   "source": [
    "# 2.2 Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a4d3d336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6a251705",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_ypred1 = dt.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f4f7d041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9981103964533595"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytest,dt_ypred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a0ed0f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9975475502752194"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(ytest,dt_ypred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3cf9cc72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9986723651905065"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(ytest,dt_ypred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "761c76f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.998109640831758"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(ytest,dt_ypred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15448ce",
   "metadata": {},
   "source": [
    "# 2.3 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9439692a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6bf220b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_ypred1 = rf.predict(xtestst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "84ac33b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999000690432065"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytest,rf_ypred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1e09b0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9997999854534875"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(ytest,rf_ypred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7d4ac959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(ytest,rf_ypred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ee9cddd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998999827242887"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(ytest,rf_ypred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f716c32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.945102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DTC</td>\n",
       "      <td>0.998110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.999900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Models  Accuracy\n",
       "0     LR  0.945102\n",
       "1    DTC  0.998110\n",
       "2     rf  0.999900"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ACCURACY CHECK\n",
    "final_data1 = pd.DataFrame({'Models':['LR','DTC','rf'],\n",
    "             'Accuracy':[accuracy_score(ytest,lr_ypred1),\n",
    "                         accuracy_score(ytest,dt_ypred1),\n",
    "                         accuracy_score(ytest,rf_ypred1)]})\n",
    "final_data1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4d0222",
   "metadata": {},
   "source": [
    "# Model Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ee7b2270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF = RandomForestClassifier()\n",
    "RF.fit(xres,yres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c6602afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0ffaf260",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CC Fraud Detection.pickle','wb') as f:\n",
    "    pickle.dump(RF,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b6070b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e1f9dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59a0c18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfd599a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405691cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1266748c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
